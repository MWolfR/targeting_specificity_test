{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import subprocess\n",
    "import pandas\n",
    "import numpy\n",
    "import targeting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "First, we specify where to find the Helstaedter connectome dataset. Adjust paths to match your file system! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileurls = {'dendrites': 'https://l4dense2019.brain.mpg.de/webdav/dendrites.hdf5',\n",
    "            'synapses': 'https://l4dense2019.brain.mpg.de/webdav/synapses.hdf5',\n",
    "            'axons': 'https://l4dense2019.brain.mpg.de/webdav/axons.hdf5'}\n",
    "\n",
    "local_data_dir = '/gpfs/bbp.cscs.ch/home/reimann/data/Helmstaedter_results'\n",
    "if not os.path.exists(local_data_dir):\n",
    "    os.makedirs(local_data_dir)\n",
    "\n",
    "filenames = dict([(k, os.path.join(local_data_dir, os.path.split(v)[1]))\n",
    "                 for k, v in fileurls.items()])\n",
    "for k in filenames.keys():\n",
    "    if not os.path.exists(filenames[k]):\n",
    "        print(\"Downloading {fn}\".format(fn=fileurls[k]))\n",
    "        subprocess.check_call([\"wget\", \"--no-check-certificate\", \"-O\", filenames[k], fileurls[k]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the data. We load data for excitatory and inhibitory connections separately. We set min_n_dendrite=10 and min_n_axon=10 to indicate that post- and pre-synaptic fragments with fewer than 10 synapses should be filtered out, as in the Science paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inh = targeting.Helmstaedter_results(filenames, ['inhibitory'], min_n_dendrite=10, min_n_axon=10)\n",
    "data_exc = targeting.Helmstaedter_results(filenames, ['corticocortical', 'thalamocortical'], min_n_dendrite=10, min_n_axon=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get an overview of what we have loaded. Note: The Science paper reports 5,894 excitatory axons and 893 inhibitory axons with 153,171 synapses in total. We do not reach exactly the same numbers, likely because our filtering for a minimum of 10 synapses per fragment was implemented differently. However, our numbers get very close and as you will see later, we can reproduce their panels 4 D, E, F and G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_inh.res)\n",
    "print(data_exc.res)\n",
    "print(\"\"\"There are {n_exc} synapses from {l_exc} excitatory axons\n",
    "      and {n_inh} synapses from {l_inh} inhibitory axons\"\"\".format(n_exc=data_exc.res.values.sum(),\n",
    "                                                                   n_inh=data_inh.res.values.sum(),\n",
    "                                                                  l_exc=len(data_exc),\n",
    "                                                                  l_inh=len(data_inh)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating the Science paper results\n",
    "Let's start by recreating panel 4 D. To plot the results for individual axons, we concatenate the results for excitatory and inhibitory axons (data_inh + data_exc, the plus operator concatenates results) and then normalize each row (.normalized()).\n",
    "\n",
    "Then, we use the .fit_all function to get the probabilities to target each type of postsynaptic structure. To get the overall means, we use targeting.trivial_fit as fitting function on the concatenated data. For the probabilities estimated under the \"first hit\" model we use targeting.max_likelihood for the fit, and we call it on excitatory and inhibitory axons separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_to_idx = {'SOM': 0, 'PD': 1, 'SD': 2, 'AD': 3, 'AIS': 4, 'OTHER': -1}\n",
    "idx_to_type = dict([(v, k) for k, v in type_to_idx.items()])\n",
    "\n",
    "\n",
    "def plot_a_column(ax, data, column_name):\n",
    "    base_x = type_to_idx[column_name]\n",
    "    if base_x < 0:\n",
    "        return\n",
    "    y = data[column_name]\n",
    "    x = base_x + numpy.random.rand(len(y)) * 0.4 - 0.2\n",
    "    ax.plot(x, y, ls='None', marker='.', color='grey', ms=2)\n",
    "\n",
    "def plot_mean_column(ax, data_mn, data_fit_exc, data_fit_inh, column_name):\n",
    "    base_x = type_to_idx[column_name]\n",
    "    y_mn = data_mn[column_name]\n",
    "    y_inh = data_fit_inh[column_name]\n",
    "    ax.plot([base_x - 0.25, base_x + 0.25], [y_mn, y_mn], color='black')\n",
    "    ax.plot([base_x + 0.35, base_x + 0.2], [y_inh, y_inh], color='black', marker='<')\n",
    "    if column_name in data_fit_exc:\n",
    "        y_exc = data_fit_exc[column_name]\n",
    "        ax.plot([base_x - 0.35, base_x - 0.2], [y_exc, y_exc], color='pink', marker='>')\n",
    "\n",
    "def fig_4_d(data_exc, data_inh):\n",
    "    from matplotlib import pyplot as plt\n",
    "    data_all = data_inh + data_exc\n",
    "    normalized_all = data_all.normalized()\n",
    "    data_mn = data_all.fit_all(targeting.trivial_fit)\n",
    "    data_fit_exc = data_exc.fit_all(targeting.max_likelihood)\n",
    "    data_fit_inh = data_inh.fit_all(targeting.max_likelihood)\n",
    "    data_fit_exc.pop('OTHER'); data_fit_inh.pop('OTHER')\n",
    "    print(\"\"\"Results of the 'first hit' binomial model fit:\n",
    "    Excitatory (%):\\n{res_exc}\n",
    "    Inhibitory (%):\\n{res_inh}\"\"\".format(res_exc=str(100*data_fit_exc),\n",
    "                                   res_inh=str(100*data_fit_inh)))\n",
    "    ax = plt.figure(figsize=(3.5,5)).add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    for col in data_fit_inh.index:\n",
    "        plot_a_column(ax, normalized_all.res, col)\n",
    "        plot_mean_column(ax, data_mn, data_fit_exc, data_fit_inh, col)\n",
    "    idxx = sorted(idx_to_type.keys())\n",
    "    ax.set_xticks(idxx[1:])\n",
    "    ax.set_xticklabels([idx_to_type[i] for i in idxx[1:]])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "\n",
    "fig_4_d(data_exc, data_inh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's recreate panels 4 E and F.\n",
    "For this, we first generate control binomial models using the probabilities estimated under the \"first hit\" model (targeting.binomial_model with targeting.max_likelihood estimators). We also oversample these models five times, i.e. we generate data for five times the number of axons. This will give us a more robust distribution for the controls. Alternatively, we could use the analytical binomial distributions for identical results.\n",
    "\n",
    "Note that when the binomial model is created, it complains that the probabilities don't add up to one. This is possible because the \"first hit\" model fits for the various types of postsynaptic structures (\"AD\", \"PD\", \"SD\", \"SOM\", \"AIS\") independently. Importantly, the \"first hit\" model will underestimate probabilities for ground truth distributions that are bimodal with one peak at zero and another above zero, because the fit only takes into account what fraction of the distribution is larger than zero. We can see this in the plot above, where for almost all postsynaptic structures the overall mean is above the \"first hit\" estimate for *both* excitatory and inhibitory axons.\n",
    "\n",
    "The model compensates for this by adding unassigned probability mass to the \"OTHER\" postsynaptic structures that are ignored in the following analysis. This is also what is implicitly done in the Science paper. However it should be noted that at that point it is no surprise that we find axons with an unexpectedly high fraction of synapses onto certain postsynaptic structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_control = 1\n",
    "\n",
    "def plot_single_panel(ax, data, ctrl, column_name):\n",
    "    bins = numpy.linspace(0, 1, 31)\n",
    "    H_data = numpy.histogram(data.res[column_name], bins=bins)[0]\n",
    "    H_ctrl = (1.0 / oversample_control) * numpy.histogram(ctrl.res[column_name], bins=bins)[0]\n",
    "    ax.bar(bins[:-1], H_ctrl, width=(bins[1] - bins[0]), color=\"grey\", label=\"expcected\")\n",
    "    ax.bar(bins[:-1], H_data, width=(bins[1] - bins[0]), color=\"None\", edgecolor='black', label=\"data\")\n",
    "    ax.set_title(column_name)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "def fig_4_e_f(data_exc, data_inh, bino_mdl_exc, bino_mdl_inh):\n",
    "    from matplotlib import pyplot as plt\n",
    "    \n",
    "    bino_fit_exc = bino_mdl_exc.fit_all(targeting.trivial_fit)\n",
    "    bino_fit_inh = bino_mdl_inh.fit_all(targeting.trivial_fit)\n",
    "    data_fit_exc = data_exc.fit_all(targeting.trivial_fit)\n",
    "    data_fit_inh = data_inh.fit_all(targeting.trivial_fit)\n",
    "    \n",
    "    print(\"\"\"Overall means for the 'first hit' binomial model (should be about the same as the fitted values above):\n",
    "    Excitatory (%):\\n{res_exc}\n",
    "    Inhibitory (%):\\n{res_inh}\\n\"\"\".format(res_exc=str(100*bino_fit_exc),\n",
    "                                   res_inh=str(100*bino_fit_inh)))\n",
    "    \n",
    "    print(\"\"\"To compare, here the mean for the data:\n",
    "    Excitatory (%):\\n{res_exc}\n",
    "    Inhibitory (%):\\n{res_inh}\\n\"\"\".format(res_exc=str(100*data_fit_exc),\n",
    "                                   res_inh=str(100*data_fit_inh)))\n",
    "    \n",
    "    data_exc = data_exc.normalized()\n",
    "    data_inh = data_inh.normalized()\n",
    "    bino_mdl_exc = bino_mdl_exc.normalized()\n",
    "    bino_mdl_inh = bino_mdl_inh.normalized()\n",
    "    \n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(3, 6))\n",
    "    for col in data_exc.res.columns:\n",
    "        if type_to_idx[col] >= 0:\n",
    "            ax = plt.subplot(3, 1, i)\n",
    "            plot_single_panel(ax, data_exc, bino_mdl_exc, col)\n",
    "            if i < 3: ax.set_xticks([])\n",
    "            if i == 3: plt.legend()\n",
    "            i = i + 1\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    for col in data_inh.res.columns:\n",
    "        if type_to_idx[col] >= 0:\n",
    "            ax = plt.subplot(3, 2, i)\n",
    "            plot_single_panel(ax, data_inh, bino_mdl_inh, col)\n",
    "            if i < 4: ax.set_xticks([])\n",
    "            if i == 4: plt.legend()\n",
    "            i = i + 1\n",
    "\n",
    "\n",
    "bino_mdl_exc = targeting.binomial_model(data_exc, targeting.max_likelihood, oversample=oversample_control)\n",
    "bino_mdl_inh = targeting.binomial_model(data_inh, targeting.max_likelihood, oversample=oversample_control)\n",
    "fig_4_e_f(data_exc, data_inh, bino_mdl_exc, bino_mdl_inh)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, recreate panel 4 g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_upper_panel(ax, sums_exc, sums_inh):\n",
    "    ax.plot(numpy.zeros_like(sums_exc), sums_exc, marker='o', color='black')\n",
    "    ax.plot(numpy.ones_like(sums_inh), sums_inh, marker='o', color='black')\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['EXC', 'INH'])\n",
    "    ax.set_ylabel('Frac. of spec. axons')\n",
    "    ax.set_xlim([-0.5, 1.5])\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "def plot_lower_panel(ax, rel_exc, rel_inh):\n",
    "    order_exc = ['SD', 'AD', 'PD']\n",
    "    col_exc = ['purple', 'orange', 'red']\n",
    "    order_inh = ['SD', 'AD', 'PD', 'AIS', 'SOM']\n",
    "    col_inh = ['purple', 'orange', 'red', 'green', 'blue']\n",
    "    rel_array_exc = numpy.array([[exc[k] for k in order_exc]\n",
    "                                for exc in rel_exc])\n",
    "    rel_array_inh = numpy.array([[inh[k] for k in order_inh]\n",
    "                                for inh in rel_inh])\n",
    "\n",
    "    x_exc = numpy.linspace(-0.3, 0.3, len(rel_array_exc) + 1)\n",
    "    x_exc = 0.5 * (x_exc[1:] + x_exc[:-1])\n",
    "    x_inh = numpy.linspace(0.7, 1.3, len(rel_array_inh) + 1)\n",
    "    x_inh = 0.5 * (x_inh[1:] + x_inh[:-1])\n",
    "\n",
    "    bottom = numpy.zeros(len(x_exc))\n",
    "    for i in range(len(order_exc)):\n",
    "        ax.bar(x_exc, rel_array_exc[:, i], bottom=bottom, color=col_exc[i], width=x_exc[1]-x_exc[0])\n",
    "        bottom = bottom + rel_array_exc[:, i]\n",
    "\n",
    "    bottom = numpy.zeros(len(x_inh))\n",
    "    for i in range(len(order_inh)):\n",
    "        ax.bar(x_inh, rel_array_inh[:, i], bottom=bottom, color=col_inh[i], width=x_inh[1]-x_inh[0])\n",
    "        bottom = bottom + rel_array_inh[:, i]\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['EXC', 'INH'])\n",
    "    ax.set_ylabel('Targetin specificity')\n",
    "    \n",
    "\n",
    "def fig_4_g(data_exc, data_inh, bino_mdl_exc, bino_mdl_inh, target_rates=[0.05, 0.1, 0.15, 0.2, 0.25, 0.3]):\n",
    "    from matplotlib import pyplot as plt\n",
    "    targeting_exc = [targeting.significant_targeting_fraction(data_exc, bino_mdl_exc, target_rate)\n",
    "                     for target_rate in target_rates]\n",
    "    targeting_inh = [targeting.significant_targeting_fraction(data_inh, bino_mdl_inh, target_rate)\n",
    "                     for target_rate in target_rates]\n",
    "    tgt_sum_exc = [numpy.sum(list(_tgt.values())) for _tgt in targeting_exc]\n",
    "    tgt_sum_inh = [numpy.sum(list(_tgt.values())) for _tgt in targeting_inh]\n",
    "    \n",
    "    fig = plt.figure(figsize=(3, 6))\n",
    "    ax = plt.subplot(2, 1, 1)\n",
    "    plot_upper_panel(ax, tgt_sum_exc, tgt_sum_inh)\n",
    "    rel_exc = [dict([(k, v / sm) for k, v in tgt.items()]) for tgt, sm in zip(targeting_exc, tgt_sum_exc)]\n",
    "    rel_inh = [dict([(k, v / sm) for k, v in tgt.items()]) for tgt, sm in zip(targeting_inh, tgt_sum_inh)]\n",
    "\n",
    "    plot_lower_panel(plt.subplot(2, 1, 2), (rel_exc[0], rel_exc[-1]), (rel_inh[0], rel_inh[-1]))\n",
    "\n",
    "fig_4_g(data_exc, data_inh, bino_mdl_exc, bino_mdl_inh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we repeat the whole analysis with a negative control model: We use from the start a binomial model with the same average probabilities for each postsynaptic structures as the data. This control must yield the same results for \"data\" and \"expected\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_ctrl_exc = targeting.binomial_model(data_exc, targeting.trivial_fit)\n",
    "negative_ctrl_inh = targeting.binomial_model(data_inh, targeting.trivial_fit)\n",
    "negative_ctrl_bino_exc = targeting.binomial_model(negative_ctrl_exc, targeting.max_likelihood, oversample=oversample_control)\n",
    "negative_ctrl_bino_inh = targeting.binomial_model(negative_ctrl_inh, targeting.max_likelihood, oversample=oversample_control)\n",
    "\n",
    "print(\"Generating panels 4 D, E, F for a negative control model that should show no indication of targeting!\")\n",
    "\n",
    "fig_4_d(negative_ctrl_exc, negative_ctrl_inh)\n",
    "fig_4_e_f(negative_ctrl_exc, negative_ctrl_inh, negative_ctrl_bino_exc, negative_ctrl_bino_inh)\n",
    "fig_4_g(negative_ctrl_exc, negative_ctrl_inh, negative_ctrl_bino_exc, negative_ctrl_bino_inh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sanity check was successful.\n",
    "\n",
    "# A control model recreates the results *without* targeting specifity\n",
    "However, I do not believe the authors interpretation of their results as indication of targeting specificity of individual axons is valid.\n",
    "\n",
    "I developed a competing control model that recreates the results *without* any targeting specificity. The model works as follows:\n",
    "First, it uses a binomial model with increased out-degrees (i.e. higher number of synapses per axon) to generate synapse 'candidates'. Then, it groups candidates that are targeting the same type of postsynaptic structure into groups of a specified size. Finally, each group of candidates is either accepted or rejected with a fixed, independent probability. Accepted groups lead to the formation of a synapse in this model. \n",
    "\n",
    "The acceptance probability is balanced with the increase of out-degrees in the initial binomial model, such that the final out-degrees match the reference model.\n",
    "\n",
    "This is inspired by the following considerations: We can consider each time an axons gets close enough to a dendrite to theoretically form a synapse as a potential synapse or apposition. It has long been known that the number of potential synapses is much higher than the number of actual synapses. We explicitly recreate this hypothesis by first generating candidates, then accepting or rejecting them. Both processes are binomial without any specific targeting mechanisms.\n",
    "\n",
    "The crucial thing that we are introducing is that we group a number of candidates (onto the same postsynaptic structure class) together and either accept or reject them together. This introduces statistical dependence between the first and further synapses onto a given postsynaptic structure class, but cannot be interpreted as a form of targeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filling_fraction = 0.2\n",
    "n_sampled_together = 3\n",
    "cand_ctrl_exc = targeting.subsample_from_appositions_model(data_exc, targeting.trivial_fit,\n",
    "                                                          filling_fraction, n_sampled_together)\n",
    "cand_ctrl_inh = targeting.subsample_from_appositions_model(data_inh, targeting.trivial_fit,\n",
    "                                                          filling_fraction, n_sampled_together)\n",
    "# Generate binomial model fits based on the \"first hit\" model.\n",
    "cand_ctrl_bino_exc = targeting.binomial_model(cand_ctrl_exc, targeting.max_likelihood, oversample=oversample_control)\n",
    "cand_ctrl_bino_inh = targeting.binomial_model(cand_ctrl_inh, targeting.max_likelihood, oversample=oversample_control)\n",
    "\n",
    "print(\"Generating panels 4 D, E, F for a candidate control model that might show indication of targeting!\")\n",
    "fig_4_d(cand_ctrl_exc, cand_ctrl_inh)\n",
    "fig_4_e_f(cand_ctrl_exc, cand_ctrl_inh, cand_ctrl_bino_exc, cand_ctrl_bino_inh)\n",
    "fig_4_g(cand_ctrl_exc, cand_ctrl_inh, cand_ctrl_bino_exc, cand_ctrl_bino_inh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more sanity check of our \"subsample_from_appositions\" model. If we set n_sampled_together to 1, then candidates are grouped into groups of size one, i.e. they are not grouped at all. In that case, the model should be reducable to a simple binomial model and once again, in the result \"data\" and \"expected\" should be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sampled_together = 1\n",
    "cand_ctrl_exc = targeting.subsample_from_appositions_model(data_exc, targeting.trivial_fit,\n",
    "                                                          filling_fraction, n_sampled_together)\n",
    "cand_ctrl_inh = targeting.subsample_from_appositions_model(data_inh, targeting.trivial_fit,\n",
    "                                                          filling_fraction, n_sampled_together)\n",
    "\n",
    "cand_ctrl_bino_exc = targeting.binomial_model(cand_ctrl_exc, targeting.max_likelihood, oversample=oversample_control)\n",
    "cand_ctrl_bino_inh = targeting.binomial_model(cand_ctrl_inh, targeting.max_likelihood, oversample=oversample_control)\n",
    "\n",
    "print(\"Generating panels 4 D, E, F for a sanity check control that should not show indication of targeting!\")\n",
    "fig_4_d(cand_ctrl_exc, cand_ctrl_inh)\n",
    "fig_4_e_f(cand_ctrl_exc, cand_ctrl_inh, cand_ctrl_bino_exc, cand_ctrl_bino_inh)\n",
    "fig_4_g(cand_ctrl_exc, cand_ctrl_inh, cand_ctrl_bino_exc, cand_ctrl_bino_inh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
